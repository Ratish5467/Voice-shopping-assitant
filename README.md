The approach followed in this project is organized and segmented, which helps develop a complete functionality of a Voice-Based Shopping Assistant that will serve under the MERN stack. The system will support most users to browse product selections, maintain their shopping cart and perform tasks both by the use of graphical user interface (GUI) controls and voice commands. This started by defining the system architecture, which was followed by the division of the project into two separate modules: a frontend component (developed with Vite and React) and a backend component (developed with Node.js, Express, and MongoDB).

RESTful APIs were developed on the server-side with the help of the Express framework to handle authentication, item management, pricing and operations of the user. MongoDB Atlas was used both as the main database and as a platform of authentication with the use of JSON Web Token (JWT). There was the implementation of Cross-origin Resource Sharing (CORS) policies, environment-driven setting, and production-scale deployments on Railway to support both local and hosted environments.

React (Vite) was used to build the client side to reduce build time and increase developer experience. Natural language processing is enabled by a custom voice recognition module, which extracts commands like add two apples, and remove sugar from cart. The user interface includes reusable elements, fluid animation and responsive designs that can handle the desktop and mobile devices. The frontend can reach backend APIs over Axios, and API routing is controlled by the environment variables (VITEAPIURL).

Finally, the app was launched on Vercel (frontend) and Railway (backend), thus being able to be scaled and perform at high rates, as well as provide the user experience that feels smooth. Testing included the API validation, the accuracy of voice command test, and end-to-end flow test.
